{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2ed25be914b48e3bcbcedd1692728dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8d446fb46554e3a9b61b46be6b2f988",
              "IPY_MODEL_270025eef8dd466fa3eb294b93dbde36",
              "IPY_MODEL_04264d70f6f74b00bb7ea4d1482e4776"
            ],
            "layout": "IPY_MODEL_b892a950fb674f368cf5cf9f18be2848"
          }
        },
        "a8d446fb46554e3a9b61b46be6b2f988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_189968e21bf54e338e97a9793b61cb1c",
            "placeholder": "​",
            "style": "IPY_MODEL_3e56940097904574b7f112fd43e447c9",
            "value": "model.safetensors: 100%"
          }
        },
        "270025eef8dd466fa3eb294b93dbde36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ebd8857ae5430fbe59c093e0d7153d",
            "max": 5964186429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e2907aeaa0642a5ad93dd77697064fb",
            "value": 5964186429
          }
        },
        "04264d70f6f74b00bb7ea4d1482e4776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774a102384db476d870297efe511a494",
            "placeholder": "​",
            "style": "IPY_MODEL_932ce5361e90439f989568abb75c8d85",
            "value": " 5.96G/5.96G [00:18&lt;00:00, 327MB/s]"
          }
        },
        "b892a950fb674f368cf5cf9f18be2848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189968e21bf54e338e97a9793b61cb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e56940097904574b7f112fd43e447c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7ebd8857ae5430fbe59c093e0d7153d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2907aeaa0642a5ad93dd77697064fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "774a102384db476d870297efe511a494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932ce5361e90439f989568abb75c8d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98bb67cc1a6244ec8fd1bf08d3592355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df8cc13a4b724adebd31c8847adc1567",
              "IPY_MODEL_e5a3dbfc38b24f3b8dc1f5fcaf863758",
              "IPY_MODEL_d72115185b6745eea999373dda38d45b"
            ],
            "layout": "IPY_MODEL_2fc91054bb54496cbb6f40511c7e4ef6"
          }
        },
        "df8cc13a4b724adebd31c8847adc1567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ad2658a591419086062cd41abaaead",
            "placeholder": "​",
            "style": "IPY_MODEL_4c392c57c06b4a3e8cf5e61032562d2b",
            "value": "generation_config.json: 100%"
          }
        },
        "e5a3dbfc38b24f3b8dc1f5fcaf863758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b498a1fe159242e3b5d09c46e8ded66f",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7633b0a6804291b5e5fdb14a96f611",
            "value": 235
          }
        },
        "d72115185b6745eea999373dda38d45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea3d6ef411e4644a747cad29b5085a4",
            "placeholder": "​",
            "style": "IPY_MODEL_009cd946919a445497d024eedf2f2a6f",
            "value": " 235/235 [00:00&lt;00:00, 29.7kB/s]"
          }
        },
        "2fc91054bb54496cbb6f40511c7e4ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ad2658a591419086062cd41abaaead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c392c57c06b4a3e8cf5e61032562d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b498a1fe159242e3b5d09c46e8ded66f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7633b0a6804291b5e5fdb14a96f611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ea3d6ef411e4644a747cad29b5085a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009cd946919a445497d024eedf2f2a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f8b33ad0ea4264ac94142385dddf14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9133ede19b408f96fdbbd28aec6af3",
              "IPY_MODEL_cc1d9f654d054a8ca62fafca008b09a8",
              "IPY_MODEL_f4a0e044f1734cc39b1bef223fde5e09"
            ],
            "layout": "IPY_MODEL_f7496334449c49f09170e560de0431cd"
          }
        },
        "7b9133ede19b408f96fdbbd28aec6af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f9cc63148a436d885e486f9d683429",
            "placeholder": "​",
            "style": "IPY_MODEL_147462826dd4494db48cc9bf3d176ea1",
            "value": "Filter: 100%"
          }
        },
        "cc1d9f654d054a8ca62fafca008b09a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea6d521c75e240dd8a09a09652961df2",
            "max": 800000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_221717a85d57454abf609f2b2da70c2f",
            "value": 800000
          }
        },
        "f4a0e044f1734cc39b1bef223fde5e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d185666b564258bebc3dbf7c6550b0",
            "placeholder": "​",
            "style": "IPY_MODEL_a7c955a08dd842758b9731eca9f7efde",
            "value": " 800000/800000 [00:21&lt;00:00, 55140.28 examples/s]"
          }
        },
        "f7496334449c49f09170e560de0431cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f9cc63148a436d885e486f9d683429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147462826dd4494db48cc9bf3d176ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea6d521c75e240dd8a09a09652961df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221717a85d57454abf609f2b2da70c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61d185666b564258bebc3dbf7c6550b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c955a08dd842758b9731eca9f7efde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4bab014120f411fa355b0675a5ff8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6feb1e4f2784ddba094048a45be0a19",
              "IPY_MODEL_f479f06f8955403b8c081dfbfd36354d",
              "IPY_MODEL_42482ff148b44f17af9737c9be27dcb8"
            ],
            "layout": "IPY_MODEL_99f1016bf92e4f6f9e3a022f0f35a116"
          }
        },
        "d6feb1e4f2784ddba094048a45be0a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870e8b32ed0947a592fb252da0d4dec0",
            "placeholder": "​",
            "style": "IPY_MODEL_09dbea5b37f24702a086afd73919f676",
            "value": "Filter: 100%"
          }
        },
        "f479f06f8955403b8c081dfbfd36354d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15776f1a3dbd4c9a82d8cedaec1aad20",
            "max": 800000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cba01cea5ed43d6a5276db54cc5aa66",
            "value": 800000
          }
        },
        "42482ff148b44f17af9737c9be27dcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63133b65c02b4feeaa7cf1b42e9751d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ce48d46d0d10461d9cd59d39a2934536",
            "value": " 800000/800000 [00:14&lt;00:00, 54871.91 examples/s]"
          }
        },
        "99f1016bf92e4f6f9e3a022f0f35a116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870e8b32ed0947a592fb252da0d4dec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09dbea5b37f24702a086afd73919f676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15776f1a3dbd4c9a82d8cedaec1aad20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cba01cea5ed43d6a5276db54cc5aa66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63133b65c02b4feeaa7cf1b42e9751d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce48d46d0d10461d9cd59d39a2934536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc5cae333c7b4a0594d3a959bc6ec0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e49c0a1563f4a71886c4bad8269d19a",
              "IPY_MODEL_256c0ce356b645ac829ee91df0845453",
              "IPY_MODEL_770d1402841b4e3391b742c02ad5005d"
            ],
            "layout": "IPY_MODEL_ac2b632988cb4eb18d335cc7563b588a"
          }
        },
        "7e49c0a1563f4a71886c4bad8269d19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a0eb44b1dc45b18dfa15bec3775589",
            "placeholder": "​",
            "style": "IPY_MODEL_c2fb71b3526e464786bd7835a3d31607",
            "value": "Saving the dataset (2/2 shards): 100%"
          }
        },
        "256c0ce356b645ac829ee91df0845453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb44f3baa67466c8c481c52980cfaa6",
            "max": 795000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8adf472c16f428d934c4ef5daac7edb",
            "value": 795000
          }
        },
        "770d1402841b4e3391b742c02ad5005d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8439e2443464a9d853a23d828108839",
            "placeholder": "​",
            "style": "IPY_MODEL_65bbac7f7a5049b4b27e3682a663f428",
            "value": " 795000/795000 [00:08&lt;00:00, 94685.72 examples/s]"
          }
        },
        "ac2b632988cb4eb18d335cc7563b588a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a0eb44b1dc45b18dfa15bec3775589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fb71b3526e464786bd7835a3d31607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb44f3baa67466c8c481c52980cfaa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8adf472c16f428d934c4ef5daac7edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8439e2443464a9d853a23d828108839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65bbac7f7a5049b4b27e3682a663f428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74fadcca63b44378b36aa29ceb3e3be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_673e1227ffe740b992743f1907a0829d",
              "IPY_MODEL_d7e55f36ce134b619a5d7eb870ad6a23",
              "IPY_MODEL_e64d8b802567400eaa2ba1d1546d815a"
            ],
            "layout": "IPY_MODEL_12a87ac111e74545ae8c9b339bf4e8dd"
          }
        },
        "673e1227ffe740b992743f1907a0829d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8152674acdb4c8ba93ed19df3a0983f",
            "placeholder": "​",
            "style": "IPY_MODEL_d0858b30f3e047f4b7c62f95894459e4",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "d7e55f36ce134b619a5d7eb870ad6a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5211fdc0712044c1a9eaf7007601c754",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6092b23a20445f09d5918a7e0ca9db9",
            "value": 5000
          }
        },
        "e64d8b802567400eaa2ba1d1546d815a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862a230047e94882ace0b8acd324e9ad",
            "placeholder": "​",
            "style": "IPY_MODEL_b33c1ae5f1714aac8233e0461c6f3b24",
            "value": " 5000/5000 [00:00&lt;00:00, 69382.62 examples/s]"
          }
        },
        "12a87ac111e74545ae8c9b339bf4e8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8152674acdb4c8ba93ed19df3a0983f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0858b30f3e047f4b7c62f95894459e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5211fdc0712044c1a9eaf7007601c754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6092b23a20445f09d5918a7e0ca9db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "862a230047e94882ace0b8acd324e9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33c1ae5f1714aac8233e0461c6f3b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58aa098b119644e0938d025b65cc77af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75feb77fce444fa5bf31ff903cda32d2",
              "IPY_MODEL_bb1fe0f89bd34cfaa0480379ec95c857",
              "IPY_MODEL_37c48bc95fbe448cb19a9974474e4e86"
            ],
            "layout": "IPY_MODEL_f746ae3f90a145948e2c08c11940e0b6"
          }
        },
        "75feb77fce444fa5bf31ff903cda32d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd0336cac74485fbbc3558ff8097317",
            "placeholder": "​",
            "style": "IPY_MODEL_8889e8f1b57442c7a39d0554947ae5c8",
            "value": "Map: 100%"
          }
        },
        "bb1fe0f89bd34cfaa0480379ec95c857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f11394af00004c078fd1aef8b2f52d9d",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fab0d99fd042404d8a75a38f8cb264b4",
            "value": 20000
          }
        },
        "37c48bc95fbe448cb19a9974474e4e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a524d8bf22974fc1ae2f3502728ebcc9",
            "placeholder": "​",
            "style": "IPY_MODEL_75691b61457a4cf199b8f47df700b4f7",
            "value": " 20000/20000 [00:00&lt;00:00, 35539.29 examples/s]"
          }
        },
        "f746ae3f90a145948e2c08c11940e0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd0336cac74485fbbc3558ff8097317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8889e8f1b57442c7a39d0554947ae5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f11394af00004c078fd1aef8b2f52d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab0d99fd042404d8a75a38f8cb264b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a524d8bf22974fc1ae2f3502728ebcc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75691b61457a4cf199b8f47df700b4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "194a44e269604f83986c7705187c5f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e48651bb9454eddb97ab0fe95db9041",
              "IPY_MODEL_00a2399a1a4c448099c85b6f707760d6",
              "IPY_MODEL_28eba02d63124008b27092fd5b8ecd7c"
            ],
            "layout": "IPY_MODEL_55bd9d597f884cabbe905c43f035358d"
          }
        },
        "1e48651bb9454eddb97ab0fe95db9041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15cd6c76d5be43a2a67c0ea57eaee2f8",
            "placeholder": "​",
            "style": "IPY_MODEL_0a88f2f370e54fbdb8609b242fab36f5",
            "value": "Map: 100%"
          }
        },
        "00a2399a1a4c448099c85b6f707760d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538292e048734fdc84e040ce12e76ef8",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_294fdbd37609462e9529fdc9bc0b38fd",
            "value": 5000
          }
        },
        "28eba02d63124008b27092fd5b8ecd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3caf0079d41745d4a227fe32d7c3cdf3",
            "placeholder": "​",
            "style": "IPY_MODEL_4c6c0ef6df954ce1b069ed20a8c7fe56",
            "value": " 5000/5000 [00:00&lt;00:00, 33576.12 examples/s]"
          }
        },
        "55bd9d597f884cabbe905c43f035358d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cd6c76d5be43a2a67c0ea57eaee2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a88f2f370e54fbdb8609b242fab36f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538292e048734fdc84e040ce12e76ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294fdbd37609462e9529fdc9bc0b38fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3caf0079d41745d4a227fe32d7c3cdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c6c0ef6df954ce1b069ed20a8c7fe56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankirthk/CS-GY-ECE-GY-6953-7123-DL-FL25-Midterm/blob/main/DL_Midterm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Install Necessary Libraries**\n",
        "First, we need to install the required Python libraries. We'll be using the **unsloth** library, which provides highly efficient, memory-saving training methods for large language models, making it possible to fine-tune powerful models on a single GPU. We'll also install other essential libraries like `trl`, `peft`, `accelerate`, and `bitsandbytes` for the fine-tuning workflow, and `datasets`, `pandas`, and `tqdm` for data handling and tracking progress. We use `%%capture` to keep the output clean."
      ],
      "metadata": {
        "id": "QwKz9yBJidKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uv # installing via uv is much quicker\n",
        "\n",
        "!uv pip install  unsloth unsloth_zoo\n",
        "!uv pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUrAMY-MigCa",
        "outputId": "3ea93b9e-1cd9-44d9-80a8-984ed5b6dad6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uv\n",
            "  Downloading uv-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.9.7\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m91 packages\u001b[0m \u001b[2min 462ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 2.42s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 56ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.48.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcut-cross-entropy\u001b[0m\u001b[2m==25.1.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==18.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mshtab\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchao\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchao\u001b[0m\u001b[2m==0.14.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyro\u001b[0m\u001b[2m==0.9.35\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1munsloth\u001b[0m\u001b[2m==2025.11.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1munsloth-zoo\u001b[0m\u001b[2m==2025.11.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.32.post2\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 95ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1.1: Wandb setup**\n"
      ],
      "metadata": {
        "id": "_jCv3DRn-TH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "\n",
        "wandb.login()\n",
        "# Shared between both users\n",
        "WANDB_PROJECT = \"nyu_math_eval_colab_experiment5\"\n",
        "WANDB_ENTITY = \"KachraSweep-Colab\"   # replace with your team/org/user handle on W&B\n",
        "\n",
        "# Unique per user\n",
        "USER_NAME = \"Sankirth\"          # teammate sets this to their own name\n",
        "\n",
        "# Export for automatic detection\n",
        "os.environ[\"WANDB_PROJECT\"] = WANDB_PROJECT\n",
        "os.environ[\"WANDB_ENTITY\"] = WANDB_ENTITY\n",
        "os.environ[\"WANDB_RUN_GROUP\"] = \"incremental_training\"\n",
        "\n",
        "print(f\"✅ Configured for project: {WANDB_ENTITY}/{WANDB_PROJECT}\")\n",
        "print(f\"User run name prefix: {USER_NAME}\")\n"
      ],
      "metadata": {
        "id": "f8QW6UXF-TbQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a4e36d64-47b4-4302-c782-269c0c3bd97a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msk11617\u001b[0m (\u001b[33msk11617-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configured for project: KachraSweep-Colab/nyu_math_eval_colab_experiment5\n",
            "User run name prefix: Sankirth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Mount Google Drive and Set Paths**\n",
        "Mounting Google Drive is essential for this competition. It allows us to **save and load model checkpoints** and our **processed dataset**. This ensures your progress is not lost if the Colab session disconnects, enabling you to resume training where you left off. We also define a base path for all project files.\n",
        "**! IMPORTANT:** Please update the `DRIVE_BASE_PATH` variable to a path in your own Google Drive."
      ],
      "metadata": {
        "id": "I7sy5801i3SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"\\n Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n Could not mount Google Drive. Training will not be persistent. Error: {e}\")\n",
        "\n",
        "# Define a base path in your Google Drive for all competition files\n",
        "# ! UPDATE THIS PATH to your desired location in Google Drive\n",
        "# ==== Common shared base path ====\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/DL_Fall_2025_Kaggle\"\n",
        "\n",
        "# ==== Unique per-user path ====\n",
        "# Replace with your actual short name or initials\n",
        "USER_NAME = \"Sankirth\"     # or \"userB\"\n",
        "\n",
        "# ==== Subdirectories ====\n",
        "CHECKPOINT_BASE = f\"{DRIVE_BASE_PATH}/checkpoints/{USER_NAME}\"\n",
        "DATASET_BASE = f\"{DRIVE_BASE_PATH}/dataset\"\n",
        "RESULTS_BASE = f\"{DRIVE_BASE_PATH}/results\"\n",
        "\n",
        "# ==== Create directories ====\n",
        "import os\n",
        "os.makedirs(CHECKPOINT_BASE, exist_ok=True)\n",
        "os.makedirs(DATASET_BASE, exist_ok=True)\n",
        "os.makedirs(RESULTS_BASE, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Configured paths for {USER_NAME}\")\n",
        "print(f\"CHECKPOINT_BASE: {CHECKPOINT_BASE}\")"
      ],
      "metadata": {
        "id": "Tz4se5_Si4XP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ae8ca1-073a-498f-d54c-4f9941b37960"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            " Google Drive mounted successfully.\n",
            "✅ Configured paths for Sankirth\n",
            "CHECKPOINT_BASE: /content/drive/MyDrive/DL_Fall_2025_Kaggle/checkpoints/Sankirth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Load the Model and Tokenizer**\n",
        "Next, we'll load the competition-approved **Llama-3-8B** model and its tokenizer. We use **Unsloth's FastLanguageModel** for high efficiency.\n",
        "\n",
        "A crucial technique here is **4-bit Quantization** (`load_in_4bit = True`). This compresses the model's parameters, dramatically reducing GPU memory usage. This makes fine-tuning the 8-billion parameter model feasible even on free-tier GPUs. We also set a standard sequence length and let Unsloth automatically select the optimal data type (`bf16` or `fp16`)."
      ],
      "metadata": {
        "id": "4y-tv2YijFiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If starting training from scratch:"
      ],
      "metadata": {
        "id": "9hFH_EVexirK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# Configuration constants\n",
        "MAX_SEQ_LENGTH = 2048 # Standard sequence length for instruction fine-tuning\n",
        "DTYPE = None          # Auto-detect the best data type for the GPU (e.g., bfloat16)\n",
        "LOAD_IN_4BIT = True   # Enable 4-bit quantization to save memory\n",
        "\n",
        "# Clean up any existing model to free VRAM\n",
        "try:\n",
        "    del model\n",
        "except NameError:\n",
        "    pass\n",
        "except UnboundLocalError:\n",
        "    pass\n",
        "\n",
        "# Load the model and tokenizer from Hugging Face\n",
        "# Note: We use the base model, not a 4-bit pre-quantized one,\n",
        "# to ensure we start from the official weights.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B\", # Competition-approved model\n",
        "    max_seq_length = MAX_SEQ_LENGTH,\n",
        "    dtype = DTYPE,\n",
        "    load_in_4bit = LOAD_IN_4BIT,\n",
        ")\n",
        "print(f\"\\nModel '{model.config._name_or_path}' and Tokenizer loaded.\")"
      ],
      "metadata": {
        "id": "DjSJU4SRCb3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If resuming training:"
      ],
      "metadata": {
        "id": "yaMm4dVlxr-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"/content/drive/MyDrive/DL_Fall_2025_Kaggle/checkpoints/Sankirth/Sankirth_run_20000_to_40000/final_model\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "f2ed25be914b48e3bcbcedd1692728dc",
            "a8d446fb46554e3a9b61b46be6b2f988",
            "270025eef8dd466fa3eb294b93dbde36",
            "04264d70f6f74b00bb7ea4d1482e4776",
            "b892a950fb674f368cf5cf9f18be2848",
            "189968e21bf54e338e97a9793b61cb1c",
            "3e56940097904574b7f112fd43e447c9",
            "e7ebd8857ae5430fbe59c093e0d7153d",
            "3e2907aeaa0642a5ad93dd77697064fb",
            "774a102384db476d870297efe511a494",
            "932ce5361e90439f989568abb75c8d85",
            "98bb67cc1a6244ec8fd1bf08d3592355",
            "df8cc13a4b724adebd31c8847adc1567",
            "e5a3dbfc38b24f3b8dc1f5fcaf863758",
            "d72115185b6745eea999373dda38d45b",
            "2fc91054bb54496cbb6f40511c7e4ef6",
            "c2ad2658a591419086062cd41abaaead",
            "4c392c57c06b4a3e8cf5e61032562d2b",
            "b498a1fe159242e3b5d09c46e8ded66f",
            "bf7633b0a6804291b5e5fdb14a96f611",
            "7ea3d6ef411e4644a747cad29b5085a4",
            "009cd946919a445497d024eedf2f2a6f"
          ]
        },
        "id": "mNp_RfIAVGGY",
        "outputId": "76a1595c-a084-4050-a604-4a3804e74d9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.11.1: Fast Llama patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2ed25be914b48e3bcbcedd1692728dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98bb67cc1a6244ec8fd1bf08d3592355"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.11.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Advanced Dataset Preparation and Balancing**\n",
        "The raw competition dataset is massive (over 1 million samples) and may be imbalanced (skewed toward 'True' or 'False' answers).\n",
        "\n",
        "This block performs three key actions:\n",
        "1.  **Check Balance:** Analyze the distribution of 'True' and 'False' in the full dataset.\n",
        "2.  **Create a Balanced Subset:** We will sample an equal number of 'True' and 'False' examples (matching the minority class size) from the entire dataset. This is essential for preventing the model from simply predicting the majority class.\n",
        "3.  **Save/Load Balanced Data:** The balanced dataset is saved to Google Drive, so you only need to run this step once."
      ],
      "metadata": {
        "id": "VIDUGF-3jbGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the save path for balanced dataset\n",
        "save_path = f\"{DATASET_BASE}/balanced_dataset\"\n",
        "\n",
        "# Check if balanced dataset already exists\n",
        "print(f\"\\n{'='*50}\")\n",
        "if os.path.exists(save_path):\n",
        "    print(f\"Balanced dataset found at: {save_path}\")\n",
        "    print(\"Loading existing balanced dataset...\")\n",
        "    balanced_dataset = load_from_disk(save_path)\n",
        "    print(f\"Loaded {len(balanced_dataset):,} samples\")\n",
        "    print(f\"True: {sum(balanced_dataset['is_correct']):,}, False: {len(balanced_dataset) - sum(balanced_dataset['is_correct']):,}\")\n",
        "else:\n",
        "    print(\"Balanced dataset not found. Creating new balanced dataset...\")\n",
        "\n",
        "    # Load the full training dataset\n",
        "    full_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"train\")\n",
        "\n",
        "    print(f\"Total training samples: {len(full_dataset)}\")\n",
        "    print(\"\\nDataset structure:\")\n",
        "    print(full_dataset)\n",
        "\n",
        "    # Analyze class distribution\n",
        "    labels = full_dataset[\"is_correct\"]\n",
        "    true_count = sum(labels)\n",
        "    false_count = len(labels) - true_count\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"True labels:  {true_count:,} ({true_count/len(labels)*100:.2f}%)\")\n",
        "    print(f\"False labels: {false_count:,} ({false_count/len(labels)*100:.2f}%)\")\n",
        "    print(f\"Imbalance ratio: {max(true_count, false_count) / min(true_count, false_count):.2f}:1\")\n",
        "\n",
        "    # Sample equal numbers from each class\n",
        "    n_samples_per_class = 400000  # Adjust based on available samples\n",
        "    shuffled_dataset = full_dataset.shuffle(seed=42)\n",
        "\n",
        "    # Get balanced samples\n",
        "    true_samples = shuffled_dataset.filter(lambda x: x[\"is_correct\"] == True).select(range(n_samples_per_class))\n",
        "    false_samples = shuffled_dataset.filter(lambda x: x[\"is_correct\"] == False).select(range(n_samples_per_class))\n",
        "\n",
        "    # Combine and shuffle thoroughly\n",
        "    balanced_dataset = concatenate_datasets([true_samples, false_samples]).shuffle(seed=42)\n",
        "\n",
        "    print(f\"\\nBalanced dataset created: {len(balanced_dataset):,} samples\")\n",
        "    print(f\"True: {sum(balanced_dataset['is_correct']):,}, False: {len(balanced_dataset) - sum(balanced_dataset['is_correct']):,}\")\n",
        "\n",
        "    # Save to Google Drive\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    balanced_dataset.save_to_disk(save_path)\n",
        "\n",
        "    print(f\"Balanced dataset saved to: {save_path}\")\n",
        "\n",
        "# === CRITICAL: Additional shuffle to ensure no ordering artifacts ===\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"APPLYING ADDITIONAL SHUFFLE FOR ROBUSTNESS\")\n",
        "print(\"=\"*50)\n",
        "balanced_dataset = balanced_dataset.shuffle(seed=42)\n",
        "print(\"✅ Dataset re-shuffled with seed=42\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfM4diETjawe",
        "outputId": "2f4b0595-1ee2-414b-e2ca-3f2232bec27a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Balanced dataset found at: /content/drive/MyDrive/DL_Fall_2025_Kaggle/dataset/balanced_dataset\n",
            "Loading existing balanced dataset...\n",
            "Loaded 800,000 samples\n",
            "True: 400,000, False: 400,000\n",
            "\n",
            "==================================================\n",
            "APPLYING ADDITIONAL SHUFFLE FOR ROBUSTNESS\n",
            "==================================================\n",
            "✅ Dataset re-shuffled with seed=42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Create training and validation splits**\n",
        "Create training and validation splits from the balanced dataset with support for incremental training. We can train on progressively larger subsets (e.g., 10k → 30k → 50k) to iteratively improve the model while managing compute constraints.\n",
        "\n",
        "**Strategy:**\n",
        "- **Incremental Training**: Train on successive chunks of data, resuming from previous checkpoints\n",
        "- **Fixed Validation Set**: Use a consistent validation set (last 5000 samples) across all runs to reliably track improvement\n",
        "- **Versioned Checkpoints**: Automatically name checkpoints based on training indices for easy tracking"
      ],
      "metadata": {
        "id": "r2dNK1cgnH-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Incremental Training Configuration (Shared + User-Aware) ===\n",
        "from pathlib import Path\n",
        "from datasets import DatasetDict\n",
        "\n",
        "# These are already defined earlier:\n",
        "# USER_NAME, DRIVE_BASE_PATH, CHECKPOINT_BASE, DATASET_BASE\n",
        "\n",
        "# Ensure subdirectories exist\n",
        "Path(CHECKPOINT_BASE).mkdir(parents=True, exist_ok=True)\n",
        "Path(DATASET_BASE).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# === STEP 1: Create stratified train/val split (only needs to be done once) ===\n",
        "split_save_path = f\"{DATASET_BASE}/train_val_split\"\n",
        "\n",
        "if os.path.exists(split_save_path):\n",
        "    print(\"=\"*60)\n",
        "    print(\"Loading existing train/validation split...\")\n",
        "    print(\"=\"*60)\n",
        "    split_datasets = load_from_disk(split_save_path)\n",
        "    training_pool = split_datasets['train']\n",
        "    validation_dataset = split_datasets['validation']\n",
        "    print(f\"Loaded training pool: {len(training_pool):,} samples\")\n",
        "    print(f\"Loaded validation set: {len(validation_dataset):,} samples\")\n",
        "else:\n",
        "    print(\"=\"*60)\n",
        "    print(\"Creating stratified train/validation split...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    n_val_samples = 5000\n",
        "\n",
        "    # Manual stratified split since stratify_by_column doesn't work with boolean\n",
        "    # Separate True and False samples\n",
        "    true_samples = balanced_dataset.filter(lambda x: x[\"is_correct\"] == True)\n",
        "    false_samples = balanced_dataset.filter(lambda x: x[\"is_correct\"] == False)\n",
        "\n",
        "    print(f\"Total True samples: {len(true_samples):,}\")\n",
        "    print(f\"Total False samples: {len(false_samples):,}\")\n",
        "\n",
        "    # Split each class proportionally (50% of validation set from each class)\n",
        "    n_val_per_class = n_val_samples // 2\n",
        "\n",
        "    # Shuffle each class separately for random selection\n",
        "    true_shuffled = true_samples.shuffle(seed=42)\n",
        "    false_shuffled = false_samples.shuffle(seed=42)\n",
        "\n",
        "    # Create validation set (first n_val_per_class from each)\n",
        "    val_true = true_shuffled.select(range(n_val_per_class))\n",
        "    val_false = false_shuffled.select(range(n_val_per_class))\n",
        "    validation_dataset = concatenate_datasets([val_true, val_false]).shuffle(seed=42)\n",
        "\n",
        "    # Create training pool (remaining samples from each class)\n",
        "    train_true = true_shuffled.select(range(n_val_per_class, len(true_shuffled)))\n",
        "    train_false = false_shuffled.select(range(n_val_per_class, len(false_shuffled)))\n",
        "    training_pool = concatenate_datasets([train_true, train_false]).shuffle(seed=42)\n",
        "\n",
        "    # Verify balance\n",
        "    val_true_count = sum(validation_dataset[\"is_correct\"])\n",
        "    val_false_count = len(validation_dataset) - val_true_count\n",
        "    train_true_count = sum(training_pool[\"is_correct\"])\n",
        "    train_false_count = len(training_pool) - train_true_count\n",
        "\n",
        "    print(f\"\\nSplit created:\")\n",
        "    print(f\"Training pool: {len(training_pool):,} samples\")\n",
        "    print(f\"  True:  {train_true_count:,} ({train_true_count/len(training_pool)*100:.1f}%)\")\n",
        "    print(f\"  False: {train_false_count:,} ({train_false_count/len(training_pool)*100:.1f}%)\")\n",
        "    print(f\"\\nValidation set: {len(validation_dataset):,} samples\")\n",
        "    print(f\"  True:  {val_true_count:,} ({val_true_count/len(validation_dataset)*100:.1f}%)\")\n",
        "    print(f\"  False: {val_false_count:,} ({val_false_count/len(validation_dataset)*100:.1f}%)\")\n",
        "\n",
        "    # Save the split for consistency across runs\n",
        "    split_to_save = DatasetDict({\n",
        "        'train': training_pool,\n",
        "        'validation': validation_dataset\n",
        "    })\n",
        "    split_to_save.save_to_disk(split_save_path)\n",
        "    print(f\"\\nTrain/validation split saved to: {split_save_path}\")\n",
        "    print(\"   (This ensures consistent validation across all incremental training runs)\")\n",
        "\n",
        "# === STEP 2: Configure incremental training ===\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INCREMENTAL TRAINING CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_start_idx = 0        # UPDATE THIS: 0 for first run, 20000 for second, etc.\n",
        "n_train_samples = 20000    # Number of samples to train per run\n",
        "\n",
        "train_end_idx = min(train_start_idx + n_train_samples, len(training_pool))\n",
        "\n",
        "# Select current training chunk from the training pool\n",
        "train_dataset = training_pool.select(range(train_start_idx, train_end_idx))\n",
        "\n",
        "print(f\"Training pool size: {len(training_pool):,}\")\n",
        "print(f\"Current training chunk: {len(train_dataset):,} samples\")\n",
        "print(f\"  └─ Indices: {train_start_idx:,} → {train_end_idx:,}\")\n",
        "print(f\"Validation set: {len(validation_dataset):,} samples (FIXED across all runs)\")\n",
        "\n",
        "# Verify balance in current training chunk\n",
        "train_true = sum(train_dataset[\"is_correct\"])\n",
        "train_false = len(train_dataset) - train_true\n",
        "val_true = sum(validation_dataset[\"is_correct\"])\n",
        "val_false = len(validation_dataset) - val_true\n",
        "\n",
        "print(f\"\\nData Balance:\")\n",
        "print(f\"Training chunk - True: {train_true:,} ({train_true/len(train_dataset)*100:.1f}%), False: {train_false:,} ({train_false/len(train_dataset)*100:.1f}%)\")\n",
        "print(f\"Validation set - True: {val_true:,} ({val_true/len(validation_dataset)*100:.1f}%), False: {val_false:,} ({val_false/len(validation_dataset)*100:.1f}%)\")\n",
        "\n",
        "# === STEP 3: Checkpoint configuration ===\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CHECKPOINT CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "run_name = f\"{USER_NAME}_run_{train_start_idx}_to_{train_end_idx}_colab\"\n",
        "output_dir = f\"{CHECKPOINT_BASE}/{run_name}\"\n",
        "\n",
        "# Determine if we should resume from a previous checkpoint\n",
        "previous_run_name = (\n",
        "    f\"{USER_NAME}_run_{train_start_idx - n_train_samples}_to_{train_start_idx}\"\n",
        "    if train_start_idx > 0 else None\n",
        ")\n",
        "\n",
        "resume_checkpoint = None\n",
        "if previous_run_name:\n",
        "    # Check for final model first, then checkpoint-final, then latest checkpoint\n",
        "    possible_checkpoints = [\n",
        "        f\"{CHECKPOINT_BASE}/{previous_run_name}/final_model\",\n",
        "        f\"{CHECKPOINT_BASE}/{previous_run_name}/checkpoint-final\",\n",
        "    ]\n",
        "\n",
        "    for ckpt_path in possible_checkpoints:\n",
        "        if os.path.exists(ckpt_path):\n",
        "            resume_checkpoint = ckpt_path\n",
        "            break\n",
        "\n",
        "print(f\"Current user: {USER_NAME}\")\n",
        "print(f\"Current run:  {run_name}\")\n",
        "print(f\"Output dir:   {output_dir}\")\n",
        "\n",
        "if resume_checkpoint:\n",
        "    print(f\"Will resume from: {resume_checkpoint}\")\n",
        "else:\n",
        "    if train_start_idx > 0:\n",
        "        print(f\"WARNING: No previous checkpoint found!\")\n",
        "        print(f\"   Expected: {CHECKPOINT_BASE}/{previous_run_name}/\")\n",
        "        print(f\"   Starting fresh training (not recommended for incremental training)\")\n",
        "    else:\n",
        "        print(\"Starting fresh training (first run)\")\n",
        "\n",
        "print(f\"\\nFor next incremental run:\")\n",
        "print(f\"   Set train_start_idx = {train_end_idx}\")\n",
        "print(f\"   Keep n_train_samples = {n_train_samples} (or adjust)\")\n",
        "print(f\"   This will train on indices {train_end_idx:,} → {min(train_end_idx + n_train_samples, len(training_pool)):,}\")\n",
        "\n",
        "# Calculate progress\n",
        "progress = (train_end_idx / len(training_pool)) * 100\n",
        "print(f\"\\nTraining Progress: {progress:.1f}% of training pool\")\n",
        "print(f\"   ({train_end_idx:,} / {len(training_pool):,} samples)\")"
      ],
      "metadata": {
        "id": "3i3j21eNnI2u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972,
          "referenced_widgets": [
            "a6f8b33ad0ea4264ac94142385dddf14",
            "7b9133ede19b408f96fdbbd28aec6af3",
            "cc1d9f654d054a8ca62fafca008b09a8",
            "f4a0e044f1734cc39b1bef223fde5e09",
            "f7496334449c49f09170e560de0431cd",
            "17f9cc63148a436d885e486f9d683429",
            "147462826dd4494db48cc9bf3d176ea1",
            "ea6d521c75e240dd8a09a09652961df2",
            "221717a85d57454abf609f2b2da70c2f",
            "61d185666b564258bebc3dbf7c6550b0",
            "a7c955a08dd842758b9731eca9f7efde",
            "f4bab014120f411fa355b0675a5ff8e7",
            "d6feb1e4f2784ddba094048a45be0a19",
            "f479f06f8955403b8c081dfbfd36354d",
            "42482ff148b44f17af9737c9be27dcb8",
            "99f1016bf92e4f6f9e3a022f0f35a116",
            "870e8b32ed0947a592fb252da0d4dec0",
            "09dbea5b37f24702a086afd73919f676",
            "15776f1a3dbd4c9a82d8cedaec1aad20",
            "5cba01cea5ed43d6a5276db54cc5aa66",
            "63133b65c02b4feeaa7cf1b42e9751d1",
            "ce48d46d0d10461d9cd59d39a2934536",
            "cc5cae333c7b4a0594d3a959bc6ec0c0",
            "7e49c0a1563f4a71886c4bad8269d19a",
            "256c0ce356b645ac829ee91df0845453",
            "770d1402841b4e3391b742c02ad5005d",
            "ac2b632988cb4eb18d335cc7563b588a",
            "b4a0eb44b1dc45b18dfa15bec3775589",
            "c2fb71b3526e464786bd7835a3d31607",
            "ebb44f3baa67466c8c481c52980cfaa6",
            "c8adf472c16f428d934c4ef5daac7edb",
            "f8439e2443464a9d853a23d828108839",
            "65bbac7f7a5049b4b27e3682a663f428",
            "74fadcca63b44378b36aa29ceb3e3be7",
            "673e1227ffe740b992743f1907a0829d",
            "d7e55f36ce134b619a5d7eb870ad6a23",
            "e64d8b802567400eaa2ba1d1546d815a",
            "12a87ac111e74545ae8c9b339bf4e8dd",
            "b8152674acdb4c8ba93ed19df3a0983f",
            "d0858b30f3e047f4b7c62f95894459e4",
            "5211fdc0712044c1a9eaf7007601c754",
            "d6092b23a20445f09d5918a7e0ca9db9",
            "862a230047e94882ace0b8acd324e9ad",
            "b33c1ae5f1714aac8233e0461c6f3b24"
          ]
        },
        "outputId": "b519ca5e-b753-4dd2-cef7-1ce4cba0f354"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Creating stratified train/validation split...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/800000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6f8b33ad0ea4264ac94142385dddf14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/800000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4bab014120f411fa355b0675a5ff8e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total True samples: 400,000\n",
            "Total False samples: 400,000\n",
            "\n",
            "Split created:\n",
            "Training pool: 795,000 samples\n",
            "  True:  397,500 (50.0%)\n",
            "  False: 397,500 (50.0%)\n",
            "\n",
            "Validation set: 5,000 samples\n",
            "  True:  2,500 (50.0%)\n",
            "  False: 2,500 (50.0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/2 shards):   0%|          | 0/795000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc5cae333c7b4a0594d3a959bc6ec0c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74fadcca63b44378b36aa29ceb3e3be7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train/validation split saved to: /content/drive/MyDrive/DL_Fall_2025_Kaggle/dataset/train_val_split\n",
            "   (This ensures consistent validation across all incremental training runs)\n",
            "\n",
            "============================================================\n",
            "INCREMENTAL TRAINING CONFIGURATION\n",
            "============================================================\n",
            "Training pool size: 795,000\n",
            "Current training chunk: 20,000 samples\n",
            "  └─ Indices: 0 → 20,000\n",
            "Validation set: 5,000 samples (FIXED across all runs)\n",
            "\n",
            "Data Balance:\n",
            "Training chunk - True: 10,001 (50.0%), False: 9,999 (50.0%)\n",
            "Validation set - True: 2,500 (50.0%), False: 2,500 (50.0%)\n",
            "\n",
            "============================================================\n",
            "CHECKPOINT CONFIGURATION\n",
            "============================================================\n",
            "Current user: Sankirth\n",
            "Current run:  Sankirth_run_0_to_20000_colab\n",
            "Output dir:   /content/drive/MyDrive/DL_Fall_2025_Kaggle/checkpoints/Sankirth/Sankirth_run_0_to_20000_colab\n",
            "Starting fresh training (first run)\n",
            "\n",
            "For next incremental run:\n",
            "   Set train_start_idx = 20000\n",
            "   Keep n_train_samples = 20000 (or adjust)\n",
            "   This will train on indices 20,000 → 40,000\n",
            "\n",
            "Training Progress: 2.5% of training pool\n",
            "   (20,000 / 795,000 samples)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Format training data**\n",
        "Define the instructional prompt template that structures how the model receives questions and solutions. We format each training example into this template and add an EOS (End of Sequence) token to signal completion. This consistent formatting helps the model learn the verification task effectively."
      ],
      "metadata": {
        "id": "v0OOA2jNn0cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The instructional prompt template for training\n",
        "training_prompt = \"\"\"You are a great mathematician and you are tasked with finding if a solution to a given maths question is correct or not. Your response should be 'True' if the solution is correct, otherwise 'False'. Below is the Question and Solution.\n",
        "Question:\n",
        "{}\n",
        "Solution:\n",
        "{}\n",
        "Output:\n",
        "{}\"\"\"\n",
        "\n",
        "# We must add an End Of Sequence (EOS) token to tell the model when a completion is finished.\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "# This function formats our data samples into the prompt template.\n",
        "def formatting_prompts_func(examples):\n",
        "    questions = examples[\"question\"]\n",
        "    solutions = examples[\"solution\"]\n",
        "    outputs = examples[\"is_correct\"]\n",
        "    texts = []\n",
        "    for question, solution, output in zip(questions, solutions, outputs):\n",
        "        # Convert boolean to string explicitly: True -> \"True\", False -> \"False\"\n",
        "        output_text = \"True\" if output else \"False\"\n",
        "\n",
        "        # Format the prompt and add the EOS token\n",
        "        text = training_prompt.format(question, str(solution), output_text) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "# Apply the formatting function to our training dataset\n",
        "formatted_train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "formatted_validation_dataset = validation_dataset.map(formatting_prompts_func, batched=True)"
      ],
      "metadata": {
        "id": "IdqzRMQ8nzSo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "58aa098b119644e0938d025b65cc77af",
            "75feb77fce444fa5bf31ff903cda32d2",
            "bb1fe0f89bd34cfaa0480379ec95c857",
            "37c48bc95fbe448cb19a9974474e4e86",
            "f746ae3f90a145948e2c08c11940e0b6",
            "afd0336cac74485fbbc3558ff8097317",
            "8889e8f1b57442c7a39d0554947ae5c8",
            "f11394af00004c078fd1aef8b2f52d9d",
            "fab0d99fd042404d8a75a38f8cb264b4",
            "a524d8bf22974fc1ae2f3502728ebcc9",
            "75691b61457a4cf199b8f47df700b4f7",
            "194a44e269604f83986c7705187c5f4e",
            "1e48651bb9454eddb97ab0fe95db9041",
            "00a2399a1a4c448099c85b6f707760d6",
            "28eba02d63124008b27092fd5b8ecd7c",
            "55bd9d597f884cabbe905c43f035358d",
            "15cd6c76d5be43a2a67c0ea57eaee2f8",
            "0a88f2f370e54fbdb8609b242fab36f5",
            "538292e048734fdc84e040ce12e76ef8",
            "294fdbd37609462e9529fdc9bc0b38fd",
            "3caf0079d41745d4a227fe32d7c3cdf3",
            "4c6c0ef6df954ce1b069ed20a8c7fe56"
          ]
        },
        "outputId": "7b0c8f78-6cf2-49fa-9d60-72cc63f27aed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58aa098b119644e0938d025b65cc77af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "194a44e269604f83986c7705187c5f4e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: LORA config**\n",
        "Configure LoRA (Low-Rank Adaptation) for parameter-efficient fine-tuning. Instead of updating all 8 billion parameters, LoRA adds small trainable adapter layers, dramatically reducing memory requirements and training time.\n",
        "\n",
        "**Key Parameters:**\n",
        "- **Rank (r=64)**: Higher rank increases model capacity to learn nuanced patterns in mathematical reasoning. Research suggests r=32-64 is optimal for complex reasoning tasks.\n",
        "- **Alpha (64)**: Standard practice is alpha = r. Can experiment with alpha = 2*r for stronger updates, or alpha < r (e.g., 16) for more stable training with high ranks.\n",
        "- **Dropout (0.05)**: Higher dropout (0.05-0.15) provides regularization, especially important when training for multiple epochs or on smaller datasets.\n",
        "- **Target Modules**: Targeting all attention and feed-forward layers. Can optionally add embedding layers or enable bias training for potential gains.\n",
        "- **Gradient Checkpointing**: Enables longer sequence lengths (up to 2048 tokens) to capture full question+solution context, especially for LaTeX-heavy or code solutions.\n",
        "\n",
        "**Note on Compute Constraints:**\n",
        "Given limited compute, focus on:\n",
        "1. Single strong model with optimal hyperparameters rather than ensembles\n",
        "2. Efficient training with gradient checkpointing\n",
        "3. Smart data sampling (incremental training on balanced data)"
      ],
      "metadata": {
        "id": "TuNY2Oktn3JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip this step if we are continuing training from a saved model file.\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "target_modules = [\n",
        "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "    \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "]\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=64,\n",
        "    target_modules=target_modules,\n",
        "    lora_alpha=64,\n",
        "    lora_dropout=0,      # must be zero for Unsloth fast patching\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n",
        "# Calculate trainable parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nTrainable params: {trainable_params:,} ({trainable_params/total_params*100:.2f}% of total)\")"
      ],
      "metadata": {
        "id": "_UXTuhOJtYv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737a3bc5-8744-4a87-e47c-b5a8876a7d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.10.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trainable params: 41,943,040 (0.90% of total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8: Trainer Config**\n",
        "Configure the Supervised Fine-Tuning Trainer with optimized hyperparameters for mathematical reasoning. Key considerations:\n",
        "\n",
        "**Training Hyperparameters:**\n",
        "- **Learning Rate (2e-5)**: Lower LR for stable fine-tuning. Too high can cause plateaus or divergence.\n",
        "- **Batch Size (effective=16)**: Balance between gradient stability and memory. Effective batch = per_device_batch_size × gradient_accumulation_steps.\n",
        "- **Warmup Steps (100)**: Longer warmup stabilizes initial training, especially important with LoRA.\n",
        "- **Epochs (3)**: Multiple epochs with validation monitoring. Single epoch often insufficient for complex reasoning.\n",
        "- **Weight Decay (0.01)**: Regularization to prevent overfitting.\n",
        "- **LR Schedule (cosine)**: Smooth learning rate decay for better convergence.\n",
        "\n",
        "**Monitoring Strategy:**\n",
        "- Evaluate on validation set every epoch\n",
        "- Save best checkpoint based on validation accuracy\n",
        "- Early stopping if performance plateaus (patience = 2 epochs)\n",
        "- Log training metrics frequently for debugging\n",
        "\n",
        "**Note:** With incremental training, we'll resume from previous checkpoint if available."
      ],
      "metadata": {
        "id": "Q9F4bumrvwGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, EarlyStoppingCallback\n",
        "import os\n",
        "\n",
        "# === Hyperparameters ===\n",
        "\n",
        "\n",
        "\n",
        "# === Output directory ===\n",
        "output_dir = f\"{CHECKPOINT_BASE}/{USER_NAME}_run_{train_start_idx}_to_{train_end_idx}\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=run_name,\n",
        "    logging_dir=f\"{output_dir}/logs\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size = 4,  # Controls the batch size per device\n",
        "    gradient_accumulation_steps = 2,  # Accumulates gradients to simulate a larger batch\n",
        "    num_train_epochs = 3,\n",
        "    learning_rate=1e-4,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    max_grad_norm=1.0,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    # lr_scheduler_kwargs={\"num_cycles\": 4},\n",
        "    fp16=not torch.cuda.is_bf16_supported(),\n",
        "    bf16=torch.cuda.is_bf16_supported(),\n",
        "    save_total_limit=1,\n",
        "    seed=3407,\n",
        "    load_best_model_at_end = True,    # Loads the best model at the end\n",
        "    report_to=\"wandb\",          # send metrics to W&B\n",
        "    eval_strategy='steps',\n",
        "    eval_steps=500,  # evalaute every 20% of the trainig step\n",
        "    save_steps=500,  # save every 20% of the trainig steps\n",
        "    metric_for_best_model=\"eval_loss\",   # NEW: Explicitly set metric\n",
        "    greater_is_better=False,\n",
        "    gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "# === Training setup ===\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset_text_field=\"text\",\n",
        "    train_dataset=formatted_train_dataset,\n",
        "    eval_dataset=formatted_validation_dataset,\n",
        "    max_seq_length=1024,\n",
        "    args=args,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "08SH7QOKv1e-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP: TRAIN MODEL ===\n",
        "import os\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training samples: {len(formatted_train_dataset):,}\")\n",
        "print(f\"Validation samples: {len(formatted_validation_dataset):,}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Model will be saved to: {output_dir}/final_model\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Train the model\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
        "if hasattr(train_result, 'metrics'):\n",
        "    print(f\"Training metrics: {train_result.metrics}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Save final model checkpoint\n",
        "final_checkpoint_path = f\"{output_dir}/final_model\"\n",
        "print(f\"Saving final model to: {final_checkpoint_path}\")\n",
        "\n",
        "os.makedirs(final_checkpoint_path, exist_ok=True)\n",
        "trainer.save_model(final_checkpoint_path)\n",
        "tokenizer.save_pretrained(final_checkpoint_path)\n",
        "\n",
        "print(f\"\\nTraining complete!\")\n",
        "print(f\"Model saved to: {final_checkpoint_path}\")\n",
        "\n",
        "# Print best checkpoint info (useful for analysis)\n",
        "if trainer.state.best_model_checkpoint:\n",
        "    print(f\"Best checkpoint: {trainer.state.best_model_checkpoint}\")\n",
        "    print(f\"Best metric: {trainer.state.best_metric:.4f}\")\n",
        "else:\n",
        "    print(\"ℹNo best checkpoint tracked (load_best_model_at_end might be False)\")"
      ],
      "metadata": {
        "id": "4KdDvKmB8F6K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "305ba85c-7ada-4f60-c6a1-7af037a6079a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 20,000 | Num Epochs = 3 | Total steps = 7,500\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251103_011359-67bh147w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sk11617-new-york-university/nyu_math_eval_colab_experiment5/runs/67bh147w' target=\"_blank\">Sankirth_run_40000_to_60000_colab</a></strong> to <a href='https://wandb.ai/sk11617-new-york-university/nyu_math_eval_colab_experiment5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sk11617-new-york-university/nyu_math_eval_colab_experiment5' target=\"_blank\">https://wandb.ai/sk11617-new-york-university/nyu_math_eval_colab_experiment5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sk11617-new-york-university/nyu_math_eval_colab_experiment5/runs/67bh147w' target=\"_blank\">https://wandb.ai/sk11617-new-york-university/nyu_math_eval_colab_experiment5/runs/67bh147w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, openai] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6903' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6903/7500 2:38:24 < 13:42, 0.73 it/s, Epoch 2.76/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.453900</td>\n",
              "      <td>0.463056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.366400</td>\n",
              "      <td>0.454211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.355100</td>\n",
              "      <td>0.440888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.299300</td>\n",
              "      <td>0.463426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-620929336.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     print(\"🟢 Starting new training run (no previous checkpoint found)\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     train_result = trainer.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Save final model checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Return inference mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"for_inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4944\u001b[0m         \"\"\"\n\u001b[1;32m   4945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"floating_point_ops\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4946\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4947\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4948\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, input_dict, exclude_embeddings)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \"\"\"\n\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mnum_parameters\u001b[0;34m(self, only_trainable, exclude_embeddings)\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexclude_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m             embedding_param_names = [\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0;34mf\"{name}.weight\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m             ]\n\u001b[1;32m   1709\u001b[0m             total_parameters = [\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m                 yield from module.named_modules(\n\u001b[0m\u001b[1;32m   2864\u001b[0m                     \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m                 yield from module.named_modules(\n\u001b[0m\u001b[1;32m   2864\u001b[0m                     \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m                 yield from module.named_modules(\n\u001b[0m\u001b[1;32m   2864\u001b[0m                     \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m                 yield from module.named_modules(\n\u001b[0m\u001b[1;32m   2864\u001b[0m                     \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m                 yield from module.named_modules(\n\u001b[0m\u001b[1;32m   2864\u001b[0m                     \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m                 yield from module.named_modules(\n\u001b[0m\u001b[1;32m   2864\u001b[0m                     \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2816\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     def named_modules(\n\u001b[0m\u001b[1;32m   2819\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8: Validation Error Analysis**\n",
        "Evaluate the fine-tuned model on the fixed validation set to identify systematic mistakes.  \n",
        "This step computes accuracy, precision, recall, and a confusion matrix, then lists misclassified examples.  \n",
        "Use it to detect whether the model is too lenient (predicts *True* too often), too skeptical (predicts *False* too often), or struggles with specific math types.  \n",
        "Insights from this step guide prompt tweaks or targeted retraining before test-set inference."
      ],
      "metadata": {
        "id": "NNvqqWIw1DYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Prepare the model for faster inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Create the prompt template for inference (no answer included)\n",
        "inference_prompt = \"\"\"You are a great mathematician and you are tasked with finding if a solution to a given maths question is correct or not. Your response should be 'True' if the solution is correct, otherwise 'False'. Below is the Question and Solution.\n",
        "Question:\n",
        "{}\n",
        "Solution:\n",
        "{}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "def parse_output(response_text: str):\n",
        "    \"\"\"\n",
        "    Parse the model's output to extract True/False prediction.\n",
        "    The response_text contains the full prompt + generated output.\n",
        "    \"\"\"\n",
        "    # Split by \"Output:\\n\" to get only the generated part\n",
        "    if \"Output:\\n\" in response_text:\n",
        "        output_part = response_text.split(\"Output:\\n\")[-1].strip()\n",
        "    else:\n",
        "        output_part = response_text.strip()\n",
        "\n",
        "    # Check what the model generated (case-insensitive for robustness)\n",
        "    output_lower = output_part.lower()\n",
        "\n",
        "    if output_lower.startswith(\"true\"):\n",
        "        return True\n",
        "    elif output_lower.startswith(\"false\"):\n",
        "        return False\n",
        "    else:\n",
        "        return None  # Malformed output\n",
        "\n",
        "\n",
        "def evaluate_accuracy(model, tokenizer, dataset, n=100, seed=42):\n",
        "    \"\"\"\n",
        "    Evaluate model accuracy on n random samples from the dataset.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    indices = random.sample(range(len(dataset)), n)\n",
        "    correct = 0\n",
        "    malformed = 0\n",
        "\n",
        "    for i in tqdm(indices, desc=\"Evaluating\"):\n",
        "        ex = dataset[i]\n",
        "        question, solution, truth = ex[\"question\"], ex[\"solution\"], ex[\"is_correct\"]\n",
        "\n",
        "        prompt = inference_prompt.format(question, str(solution))\n",
        "        inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=8,\n",
        "                temperature=0.0,\n",
        "                do_sample=False,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                use_cache=True,\n",
        "            )\n",
        "        text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        pred = parse_output(text)\n",
        "\n",
        "        if pred is None:\n",
        "            malformed += 1\n",
        "            # Optionally print malformed outputs for debugging\n",
        "            # print(f\"\\nMalformed output: {text}\")\n",
        "        else:\n",
        "            correct += int(pred == truth)\n",
        "\n",
        "    acc = correct / n\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluated {n} random samples\")\n",
        "    print(f\"Correct: {correct}/{n} ({acc*100:.1f}%)\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    if malformed > 0:\n",
        "        print(f\"Malformed outputs: {malformed}/{n} ({malformed/n*100:.1f}%)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return acc\n",
        "\n",
        "# === Optional: Detailed error analysis ===\n",
        "def detailed_error_analysis(model, tokenizer, dataset, n=100, seed=42):\n",
        "    \"\"\"\n",
        "    Analyze where the model makes mistakes.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    indices = random.sample(range(len(dataset)), n)\n",
        "\n",
        "    errors = {\n",
        "        \"false_positives\": [],  # Predicted True, actually False\n",
        "        \"false_negatives\": [],  # Predicted False, actually True\n",
        "        \"malformed\": []         # Could not parse output\n",
        "    }\n",
        "\n",
        "    for i in tqdm(indices, desc=\"Analyzing errors\"):\n",
        "        ex = dataset[i]\n",
        "        question, solution, truth = ex[\"question\"], ex[\"solution\"], ex[\"is_correct\"]\n",
        "\n",
        "        prompt = inference_prompt.format(question, str(solution))\n",
        "        inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=8,\n",
        "                temperature=0.0,\n",
        "                do_sample=False,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                use_cache=True,\n",
        "            )\n",
        "        text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        pred = parse_output(text)\n",
        "\n",
        "        if pred is None:\n",
        "            errors[\"malformed\"].append({\n",
        "                \"question\": question[:100],  # First 100 chars\n",
        "                \"output\": text.split(\"Output:\\n\")[-1] if \"Output:\\n\" in text else text\n",
        "            })\n",
        "        elif pred != truth:\n",
        "            if pred == True and truth == False:\n",
        "                errors[\"false_positives\"].append({\n",
        "                    \"question\": question[:100],\n",
        "                    \"solution\": str(solution)[:100]\n",
        "                })\n",
        "            else:\n",
        "                errors[\"false_negatives\"].append({\n",
        "                    \"question\": question[:100],\n",
        "                    \"solution\": str(solution)[:100]\n",
        "                })\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ERROR ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"False Positives (said True, was False): {len(errors['false_positives'])}\")\n",
        "    print(f\"False Negatives (said False, was True): {len(errors['false_negatives'])}\")\n",
        "    print(f\"Malformed outputs: {len(errors['malformed'])}\")\n",
        "\n",
        "    if errors[\"malformed\"]:\n",
        "        print(f\"\\nSample malformed outputs:\")\n",
        "        for i, err in enumerate(errors[\"malformed\"][:3]):  # Show first 3\n",
        "            print(f\"  {i+1}. Output: '{err['output']}'\")\n",
        "\n",
        "    return errors\n"
      ],
      "metadata": {
        "id": "TrrrIyYMoMnS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Run evaluation ===\n",
        "print(\"Starting validation evaluation...\")\n",
        "validation_accuracy = evaluate_accuracy(model, tokenizer, validation_dataset, n=500)  # Use 500 for better estimate"
      ],
      "metadata": {
        "id": "f_xQfU-yoPNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76a4458-de21-423e-b79a-330717969c1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting validation evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 500/500 [02:34<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Evaluated 500 random samples\n",
            "Correct: 424/500 (84.8%)\n",
            "Accuracy: 0.8480\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = detailed_error_analysis(model, tokenizer, validation_dataset, n=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPFiVV-5Qih",
        "outputId": "d52d2d21-d4f9-4665-d5ae-7b9f61a7185a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing errors: 100%|██████████| 200/200 [01:01<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ERROR ANALYSIS\n",
            "============================================================\n",
            "False Positives (said True, was False): 11\n",
            "False Negatives (said False, was True): 18\n",
            "Malformed outputs: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 10: Generate Submission File**\n",
        "Use the fine-tuned model to predict `is_correct` for every example in the official test set.  \n",
        "This step runs inference with the final prompt, parses each prediction as **True** or **False**, and saves results in a Kaggle-ready CSV file.  \n",
        "Before submission, open the file to confirm outputs contain only `True`/`False` values and the distribution looks reasonable.  \n",
        "Upload the resulting `submission.csv` to Kaggle to evaluate leaderboard performance."
      ],
      "metadata": {
        "id": "N73zchTX2mCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the model for faster inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Create the prompt template for inference (no answer included)\n",
        "inference_prompt = \"\"\"You are a great mathematician and you are tasked with finding if a solution to a given maths question is correct or not. Your response should be 'True' if the solution is correct, otherwise 'False'. Below is the Question and Solution.\n",
        "Question:\n",
        "{}\n",
        "Solution:\n",
        "{}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "# Select a sample from the validation set\n",
        "example_idx = 99  # Change this to test different examples\n",
        "example = validation_dataset[example_idx]\n",
        "question = example[\"question\"]\n",
        "solution = example[\"solution\"]\n",
        "truth = example[\"is_correct\"]\n",
        "\n",
        "# Format the prompt with the validation data\n",
        "inputs = tokenizer(\n",
        "    [inference_prompt.format(question, str(solution))],\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate the model's response\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=8,\n",
        "        temperature=0.0,        # Deterministic output\n",
        "        do_sample=False,        # No sampling\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        use_cache=True\n",
        "    )\n",
        "\n",
        "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "# Extract the generated prediction\n",
        "full_response = response[0]\n",
        "if \"Output:\\n\" in full_response:\n",
        "    prediction_text = full_response.split(\"Output:\\n\")[1].strip()\n",
        "else:\n",
        "    prediction_text = full_response.strip()\n",
        "\n",
        "# Parse the prediction\n",
        "prediction = None\n",
        "if prediction_text.lower().startswith(\"true\"):\n",
        "    prediction = True\n",
        "elif prediction_text.lower().startswith(\"false\"):\n",
        "    prediction = False\n",
        "\n",
        "# Print the results\n",
        "print(\"=\"*60)\n",
        "print(f\"VALIDATION EXAMPLE #{example_idx}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n#### QUESTION ####\")\n",
        "print(question)\n",
        "\n",
        "print(\"\\n#### SOLUTION ####\")\n",
        "print(solution)\n",
        "\n",
        "print(\"\\n#### MODEL'S PREDICTION ####\")\n",
        "print(f\"Raw output: '{prediction_text}'\")\n",
        "print(f\"Parsed as: {prediction}\")\n",
        "\n",
        "print(\"\\n#### CORRECT ANSWER ####\")\n",
        "print(truth)\n",
        "\n",
        "print(\"\\n#### RESULT ####\")\n",
        "if prediction == truth:\n",
        "    print(\"CORRECT!\")\n",
        "else:\n",
        "    print(\"INCORRECT\")\n",
        "    if prediction is None:\n",
        "        print(\"Warning: Could not parse model output\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "daU8uVJt2mWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd90af8-eee2-4a6e-9922-c8425e0f148c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDATION EXAMPLE #99\n",
            "============================================================\n",
            "\n",
            "#### QUESTION ####\n",
            "Elmo makes $N$ sandwiches for a fundraiser. For each sandwich he uses $B$ globs of peanut butter at $4$ cents per glob and $J$ blobs of jam at $5$ cents per blob.  The cost of the peanut butter and jam to make all the sandwiches is $\\$2.53$. Assume that  $B$, $J$, and $N$ are positive integers with $N>1$. What is the cost, in dollars, of the jam Elmo uses to make the sandwiches?\n",
            "\n",
            "#### SOLUTION ####\n",
            "Let's write down the equations to solve:\n",
            "We have $N$ sandwiches so we multiply cost of peanut butter ($4$ cents per glob * $B$ globs) and jam ($5$ cents per blob * $J$ blobs) for all sandwiches.\n",
            "Then the total cost is $2.53$.\n",
            "$4 * B * N + 5 * J * N = 2.53$\n",
            "Since we know the cost of peanut butter and jam, we can calculate $B$ and $J$.\n",
            "Let's use sympy:\n",
            "<llm-code>\n",
            "from sympy import symbols, Eq, solve\n",
            "\n",
            "# Define the variables\n",
            "N = 2\n",
            "B = symbols('B')\n",
            "J = symbols('J')\n",
            "\n",
            "eq1 = Eq(4 * B * N + 5 * J * N, 2.53)\n",
            "\n",
            "solutions = solve(eq1, (B, J))\n",
            "B_value, J_value = solutions[0]\n",
            "\n",
            "J_value\n",
            "</llm-code>\n",
            "<llm-code-output>\n",
            "J\n",
            "</llm-code-output>\n",
            "So the cost of the jam Elmo uses is $\\boxed{J \\text{ cents}}$.\n",
            "We can not calculate the value of $J$ since we don't know the value of $N$.\n",
            "\n",
            "<!---final question-->\n",
            "Question:\n",
            "Jenna picks a card from a standard deck and replaces it. She then picks a second card. What is the probability that the first card she picks is a two and the second card is a five? Express your answer as a common fraction.\n",
            "\n",
            "My solution:\n",
            "The deck has 52 cards and 4 cards for each of the suits. \n",
            "The probability of choosing a card is the number of cards we choose from divided by the total number of cards in the deck.\n",
            "So the probability of choosing a two is $\\frac{4}{52}$. The probability of choosing a five is $\\frac{4}{52}$.\n",
            "Since the first card is replaced, the second draw is independent of the first one.\n",
            "So we can just multiply the two probabilities:\n",
            "$\\frac{4}{52} * \\frac{4}{52} = \\frac{4}{2704} = \\frac{1}{676}$.\n",
            "The answer is $\\boxed{\\frac{1}{676}}$.\n",
            "\n",
            "Here is one final question for you to solve:\n",
            "\n",
            "Question:\n",
            "Ari hikes 16 miles east, then 18 miles north, then 36 miles north, and then 21 miles west. How many miles is Ari north of where she started?\n",
            "\n",
            "Your answer:\n",
            "Ari hikes 16 miles east then 18 miles north then 36 miles north and then 21 miles west.\n",
            "The answer is the distance Ari north of where she started.\n",
            "So we need to calculate the total distance from the beginning to the current position.\n",
            "Since the last part of the journey is a west direction, the distance of the journey is as follows:\n",
            "<llm-code>\n",
            "from sympy import symbols, Eq, solve\n",
            "\n",
            "x = symbols('x')\n",
            "\n",
            "distance = x + 18 + 36 + 21\n",
            "distance\n",
            "</llm-code>\n",
            "<llm-code-output>\n",
            "x + 75\n",
            "</llm-code-output>\n",
            "So the total distance is $\\boxed{x + 75}$.\n",
            "\n",
            "</subexercise>\n",
            "</exercise>\n",
            "</reference>\n",
            "```\n",
            "```\n",
            "<!---begin exercise-->\n",
            "\n",
            "<exercise>\n",
            "<reference>exercise-geometry.md</reference>\n",
            "<header>\n",
            "<title>Geometry</title>\n",
            "<subtitle>Rectangles, Circles, Triangles</subtitle>\n",
            "</header>\n",
            "\n",
            "<question>\n",
            "\n",
            "What is the area of a rectangle with a length of 10 units and a width of 4 units?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "A square has sides of length 7.5 units. What is the length of its diagonal?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "What is the length of a side of a square with an area of 36 units?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "If a circle has a diameter of 10 inches, what is the length of its circumference?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "If a circle has a circumference of 28 inches, what is the length of its radius?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "What is the area of a circle with a diameter of 16 inches?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "What is the circumference of a circle with an area of 169 square units?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "What is the area of a circle with a circumference of 28 inches?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "A triangular flag with a base of 3 feet has a height of 5 feet. What is the area of the flag?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "A triangular flag with an area of 21 square feet has a height of 7 feet. What is the length of the base?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "An equilateral triangle has a side length of 3 inches. What is the height of the triangle?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "If an equilateral triangle has a side length of 4 inches, what is the length of the perpendicular bisector of one of its sides?\n",
            "\n",
            "</question>\n",
            "<question>\n",
            "\n",
            "What is the perimeter of an equilateral triangle\n",
            "\n",
            "#### MODEL'S PREDICTION ####\n",
            "Raw output: 'False'\n",
            "Parsed as: False\n",
            "\n",
            "#### CORRECT ANSWER ####\n",
            "False\n",
            "\n",
            "#### RESULT ####\n",
            "CORRECT!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# Load the official test set\n",
        "test_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"test\")\n",
        "\n",
        "# Prepare model for inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Create the prompt template for inference (no answer included)\n",
        "inference_prompt = \"\"\"You are a great mathematician and you are tasked with finding if a solution to a given maths question is correct or not. Your response should be 'True' if the solution is correct, otherwise 'False'. Below is the Question and Solution.\n",
        "Question:\n",
        "{}\n",
        "Solution:\n",
        "{}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "# Improved function to parse 'True' or 'False' from the model's raw output\n",
        "def parse_output(response_text):\n",
        "    \"\"\"\n",
        "    Parse the model's output to extract True/False prediction.\n",
        "    \"\"\"\n",
        "    # Extract the part after \"Output:\\n\"\n",
        "    if \"Output:\\n\" in response_text:\n",
        "        output_part = response_text.split(\"Output:\\n\")[-1].strip()\n",
        "    else:\n",
        "        output_part = response_text.strip()\n",
        "\n",
        "    # Check what was generated (case-insensitive)\n",
        "    output_lower = output_part.lower()\n",
        "\n",
        "    if output_lower.startswith(\"true\"):\n",
        "        return True\n",
        "    elif output_lower.startswith(\"false\"):\n",
        "        return False\n",
        "    else:\n",
        "        # Default to False if malformed (you can also return None and handle separately)\n",
        "        print(f\"Malformed output: '{output_part[:50]}...'\")\n",
        "        return False\n",
        "\n",
        "# Store predictions and tracking info\n",
        "predictions = []\n",
        "prediction_details = []\n",
        "malformed_count = 0\n",
        "\n",
        "# Loop through the test dataset and generate a prediction for each example\n",
        "print(f\"\\nGenerating predictions for {len(test_dataset):,} test examples...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx, example in enumerate(tqdm(test_dataset, desc=\"Predicting\")):\n",
        "    question = example[\"question\"]\n",
        "    solution = example[\"solution\"]\n",
        "\n",
        "    # Format the prompt\n",
        "    prompt = inference_prompt.format(question, str(solution))\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate the prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=8,\n",
        "            temperature=0.0,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            use_cache=True\n",
        "        )\n",
        "\n",
        "    response_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "    # Parse the prediction\n",
        "    prediction = parse_output(response_text)\n",
        "    predictions.append(prediction)\n",
        "\n",
        "    # Extract just the generated output for display\n",
        "    if \"Output:\\n\" in response_text:\n",
        "        generated_output = response_text.split(\"Output:\\n\")[-1].strip()\n",
        "    else:\n",
        "        generated_output = response_text.strip()\n",
        "\n",
        "    # Track malformed outputs\n",
        "    if not (generated_output.lower().startswith(\"true\") or generated_output.lower().startswith(\"false\")):\n",
        "        malformed_count += 1\n",
        "\n",
        "    # Store details for later analysis\n",
        "    prediction_details.append({\n",
        "        'ID': idx,\n",
        "        'prediction': prediction,\n",
        "        'raw_output': generated_output,\n",
        "        'question_preview': question[:100]  # First 100 chars\n",
        "    })\n",
        "\n",
        "    # Print first 10 predictions as examples\n",
        "    if idx < 10:\n",
        "        print(f\"ID {idx:4d}: Predicted = {str(prediction):5s} | Raw: '{generated_output}'\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'ID': range(len(predictions)),\n",
        "    'is_correct': predictions\n",
        "})\n",
        "\n",
        "# Display prediction statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total predictions: {len(predictions):,}\")\n",
        "print(f\"Predicted True:  {sum(predictions):,} ({sum(predictions)/len(predictions)*100:.1f}%)\")\n",
        "print(f\"Predicted False: {len(predictions) - sum(predictions):,} ({(len(predictions) - sum(predictions))/len(predictions)*100:.1f}%)\")\n",
        "if malformed_count > 0:\n",
        "    print(f\"Malformed outputs: {malformed_count} ({malformed_count/len(predictions)*100:.1f}%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "submission_filename = f'submission_{USER_NAME}_{train_start_idx}_to_{train_end_idx}.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nSubmission file '{submission_filename}' created successfully!\")\n",
        "print(f\"   Rows: {len(submission)}\")\n",
        "print(f\"   Columns: {list(submission.columns)}\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nFirst 10 rows of submission:\")\n",
        "print(submission.head(10))\n",
        "\n",
        "# Save detailed predictions for analysis\n",
        "details_df = pd.DataFrame(prediction_details)\n",
        "details_filename = f'prediction_details_{USER_NAME}_{train_start_idx}_to_{train_end_idx}.csv'\n",
        "details_df.to_csv(details_filename, index=False)\n",
        "print(f\"\\nDetailed predictions saved to '{details_filename}'\")\n",
        "\n",
        "# Optional: Save to Google Drive\n",
        "import shutil\n",
        "drive_submission_path = f'{RESULTS_BASE}/{submission_filename}'\n",
        "shutil.copy(submission_filename, drive_submission_path)\n",
        "print(f\"Saved to Google Drive: {drive_submission_path}\")\n",
        "\n",
        "print(\"\\nYou can now download and submit to Kaggle!\")"
      ],
      "metadata": {
        "id": "_w6KY_t6WaIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 11: Save Fine-Tuned Model and Tokenizer\n",
        "Save the final fine-tuned model and tokenizer for future inference or continued training.  \n",
        "This ensures all LoRA adapter weights and tokenizer vocabulary are preserved.  \n",
        "You can later reload them with `FastLanguageModel.from_pretrained(save_dir)` to resume training or generate new predictions."
      ],
      "metadata": {
        "id": "Wl8Z-zEX3Yea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING FINAL MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create save directory\n",
        "save_dir = os.path.join(output_dir, \"final_model\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save model and tokenizer\n",
        "print(f\"Saving to: {save_dir}\")\n",
        "model.save_pretrained(save_dir)\n",
        "print(\"Model saved\")\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "print(\"Tokenizer saved\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    \"user\": USER_NAME,\n",
        "    \"train_start_idx\": train_start_idx,\n",
        "    \"train_end_idx\": train_end_idx,\n",
        "    \"n_train_samples\": len(train_dataset),\n",
        "    \"learning_rate\": args.learning_rate,\n",
        "    \"lora_r\": 64,\n",
        "    \"lora_alpha\": 128,\n",
        "}\n",
        "\n",
        "with open(os.path.join(save_dir, \"training_metadata.json\"), 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "print(\"Metadata saved\")\n",
        "\n",
        "# Verify and report\n",
        "saved_files = os.listdir(save_dir)\n",
        "total_size = sum(os.path.getsize(os.path.join(save_dir, f)) for f in saved_files)\n",
        "\n",
        "print(f\"\\nSaved {len(saved_files)} files ({total_size / (1024**3):.2f} GB)\")\n",
        "print(f\"\\nModel saved successfully!\")\n",
        "print(f\"\\nTo reload: FastLanguageModel.from_pretrained(\\\"{save_dir}\\\", load_in_4bit=True)\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "ZAEoyEYY3aW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634405ce-1cd8-4a18-93f4-68f7e552d535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model and tokenizer saved to: /content/drive/MyDrive/DL_Fall_2025_Kaggle/checkpoints/Sankirth/Sankirth_run_20000_to_40000/final_model\n",
            "You can later reload them with:\n",
            "  model, tokenizer = FastLanguageModel.from_pretrained(\"/content/drive/MyDrive/DL_Fall_2025_Kaggle/checkpoints/Sankirth/Sankirth_run_20000_to_40000/final_model\")\n"
          ]
        }
      ]
    }
  ]
}